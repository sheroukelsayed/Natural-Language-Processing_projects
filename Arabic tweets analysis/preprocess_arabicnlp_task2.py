# -*- coding: utf-8 -*-
"""Preprocess_arabicNLP_task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/188orincHOUUM5i5iKdcpNQVhVt-W1NIK
"""

from google.colab import drive
drive.mount('/content/drive')
# code for sentiment analysis : negative , positive, and neutral

!pip3 install ktrain

import tensorflow as tf
import tensorflow_hub as hub
import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import re
import unicodedata
import nltk
from nltk.corpus import stopwords
import keras
from tqdm import tqdm
import pickle
from keras.models import Model
import keras.backend as K
from sklearn.metrics import confusion_matrix,f1_score,classification_report
import matplotlib.pyplot as plt
from keras.callbacks import ModelCheckpoint
import itertools
from keras.models import load_model
from sklearn.utils import shuffle
import tensorflow as tf

!pip install pillow
import nltk
import numpy as np
import matplotlib.pyplot as plt

from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer

# Commented out IPython magic to ensure Python compatibility.
import os
import re
from tqdm import tqdm

import pandas as pd

import csv

# %matplotlib inline

def remove_diacritics(text):
    arabic_diacritics = re.compile(""" ّ    | # Tashdid
                             َ    | # Fatha
                             ً    | # Tanwin Fath
                             ُ    | # Damma
                             ٌ    | # Tanwin Damm
                             ِ    | # Kasra
                             ٍ    | # Tanwin Kasr
                             ْ    | # Sukun
                             ـ     # Tatwil/Kashida
                         """, re.VERBOSE)
    text = re.sub(arabic_diacritics, '', str(text))
    return text

!pip install emoji

import emoji
# Due to important of emoji in emotion analysis we convert it to arabic meaning 
def convert_emoji(text):

    text=emoji.demojize(text)
    text = re.sub(r'\d+', '', text)
    text = re.sub('Url', '', text)
    text = re.sub('URL', '', text)
    text = re.sub('url', '', text)
    text = re.sub('USER', '', text)
    text = re.sub("_", " ", str(text))

    text = re.sub("smiling", "سعيد", str(text))
    text = re.sub("grinning", "سعيد", str(text))
    text = re.sub("beaming", "سعيد", str(text))
    text = re.sub("laughing", "سعيد", str(text))
    text = re.sub("joy", "سعيد", str(text))
    text = re.sub("winking", "سعيد", str(text))
    text = re.sub("kiss", "سعيد", str(text))
    text = re.sub("kissing", "سعيد", str(text))

    text = re.sub("hand over mouth", "سعيد", str(text))
    text = re.sub("partying face", "سعيد", str(text))

    text = re.sub("thought balloon", "يفكر", str(text))
    text = re.sub("love-you gesture", "سعيد", str(text))

    text = re.sub("folded hands", "سعيد", str(text))
    text = re.sub("palms up togetherpartying face", "سعيد", str(text))
    text = re.sub("love-you gesture", "سعيد", str(text))

    text = re.sub("dancing", "سعيد", str(text))
    text = re.sub("rose", "سعيد", str(text))

    text = re.sub("hibiscus", "سعيد", str(text))
    text = re.sub("sunflower", "سعيد", str(text))
    text = re.sub("blossom", "سعيد", str(text))

    text = re.sub("tulip", "سعيد", str(text))
    text = re.sub("musical note", "سعيد", str(text))

    text = re.sub("musical notes", "سعيد", str(text))
    text = re.sub("musical score", "سعيد", str(text))
    text = re.sub("	saxophone", "سعيد", str(text))

    text = re.sub("guitar", "سعيد", str(text))
    text = re.sub("	violin", "سعيد", str(text))






    text = re.sub("face without mouth", "حزين", str(text))
    text = re.sub("zipper-mouth face", "حزين", str(text))
    text = re.sub("unamused face", "حزين", str(text))

    text = re.sub("	smiling face with tear", "حزين", str(text))
    text = re.sub("expressionless face", "حزين", str(text))
    text = re.sub("lying face", "حزين", str(text))
    text = re.sub("face with medical mask","حزين", str(text))
    text = re.sub("face with thermometer", "حزين", str(text))
    text = re.sub("	smiling face with tear", "حزين", str(text))

    text = re.sub("face with head-bandage", "حزين", str(text))
    text = re.sub("nauseated face", "حزين", str(text))
    text = re.sub("face vomiting", "حزين", str(text))
    text = re.sub("sneezing face", "حزين", str(text))

    text = re.sub("with crossed-out eyes", "حزين", str(text))
    text = re.sub("exploding head", "حزين", str(text))
    text = re.sub("worried", "حزين", str(text))
    text = re.sub("slightly frowning","حزين", str(text))
    text = re.sub("pleading", "حزين", str(text))

    text = re.sub("holding back tears", "حزين", str(text))
    text = re.sub("	fearful", "حزين", str(text))
    text = re.sub("anxious face with sweat", "حزين", str(text))
    text = re.sub("sad but relieved ","حزين", str(text))
    text = re.sub("crying ", "حزين", str(text))

    text = re.sub("	screaming in fear", "حزين", str(text))
    text = re.sub("confounded ", "حزين", str(text))
    text = re.sub("disappointed ", "حزين", str(text))
    text = re.sub("downcast face with sweat","حزين", str(text))
    text = re.sub("weary", "حزين", str(text))

    text = re.sub("	pouting ", "حزين", str(text))
    text = re.sub("	angry ", "حزين", str(text))
    text = re.sub("face with symbols on mouth", "حزين", str(text))
    text = re.sub("broken heart","حزين", str(text))
    text = re.sub("mending heart", "حزين", str(text))
    text = re.sub("hearts", "سعيد", str(text))
    text = re.sub("heart", "سعيد", str(text))

    text = re.sub("face", " ", str(text))
    text = re.sub("fire", " تشجيع", str(text))
    text = re.sub("_", " ", str(text))
    text = re.sub("with", " ", str(text))
    text = re.sub(" ballon", "سعيد ", str(text))
    text = re.sub("star", "سعيد ", str(text))
    text = re.sub(r'[A-Z]+', " ", str(text))
    text = re.sub(r'[a-z]+', " ", str(text))


    return text

def clean_text(text):
    text = "".join([word for word in text if word not in punctuations_list ])
    text = convert_emoji(text)
    text = remove_diacritics(text)
    tokens = word_tokenize(text)
    text = ' '.join([word for word in tokens if word not in stop_words])
    return text

def process_text(text):
    stemmer = nltk.ISRIStemmer()
    word_list = nltk.word_tokenize(text)
    #stemming
    #word_list = [stemmer.stem(w) for w in  word_list]
    return ' '.join(word_list)

nltk.download('stopwords')

nltk.download('punkt')

import nltk
from nltk.corpus import stopwords

stop_words = list(set(stopwords.words('arabic')))
print(stop_words)

arabic_stopwords = list(map(str.strip,stopwords.open('arabic')))

import re
import string
import sys
import argparse
from nltk.tokenize import word_tokenize

arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:"؟.,'{}~¦+|!”…“–ـ'''
english_punctuations = string.punctuation
punctuations_list = arabic_punctuations + english_punctuations

train=pd.read_csv('/content/drive//My Drive/NADI2022/Subtask2_TRAIN.tsv',sep='\t')
DEV=pd.read_csv('/content/drive//My Drive/NADI2022/Subtask2_DEV.tsv',sep='\t')
test=pd.read_csv('/content/drive//My Drive/NADI2022/NADI2022_Subtask2_TEST_Unlabeled.tsv',sep='\t')





lengths = train['tweet'].str.len()
argmax = np.where(lengths == lengths.max())[0]



train['tweet'].iloc[argmax].str.len()




train1= train.rename(columns = {'#1_id': 'id', '#2_content': 'content','#3_label': 'label'}, inplace = False)
DEV1= DEV.rename(columns = {'#1_id': 'id', '#2_content': 'content','#3_label': 'label'}, inplace = False)

df= df.rename(columns = {'#1_id': 'id', '#2_content': 'content','#3_label': 'label'}, inplace = False)

test1=test.rename(columns = {'#1_id': 'id', '#2_content': 'content'}, inplace = False)

train1= train1.rename(columns = {'content': 'tweet', 'label': 'label'}, inplace = False)

from sklearn.model_selection import train_test_split

train, test = train_test_split(df, test_size=0.2)

len(test1)

print('Available labels: ',train.label.unique())

train1['symbol2'] = train1['label'].map({'neg':0, 'neut':1, 'pos':2})
#DEV1['symbol2'] = DEV1['label'].map({'neg':0, 'neut':1, 'pos':2})

df['symbol2'] = df['label'].map({'neg':0, 'neut':1, 'pos':2})

train1['cleanedtext'] = train1['tweet'].apply(clean_text)
train1['new_content']=train1['cleanedtext'].apply(process_text)

DEV1['cleanedtext'] = DEV1['content'].apply(clean_text)
DEV1['new_content']= DEV1['cleanedtext'].apply(process_text)



test1['cleanedtext'] = test1['content'].apply(clean_text)
test1['new_content']=test1['cleanedtext'].apply(process_text)



from sklearn.utils import class_weight
classes=[0,1,2]
class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(train1['symbol']),y=train1['symbol'])
class_weights = dict(enumerate(class_weights))



train1.to_csv(r'/content/drive//My Drive/NADI2022/task2_processing_train_emoji2_3.csv', index=False)
DEV1.to_csv(r'/content/drive//My Drive/NADI2022/task2_processing_dev_emoji2_1.csv', index=False)

df.to_csv(r'/content/drive//My Drive/NADI2022/task2_processing_collection2.csv', index=False)

test1.to_csv(r'/content/drive//My Drive/NADI2022/task2_processing_test3.csv', index=False)



